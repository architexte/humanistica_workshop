{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b094ca9-92a9-4208-a448-ad84bd96af46",
   "metadata": {},
   "source": [
    "# Analyser les données ouvertes du patrimoine\n",
    "\n",
    "D’importantes bases de connaissance sont disponibles sous licence libre, transformant la recherche.\n",
    "Avec la possibilité de mobiliser les méthodes computationnelles sur un volume considérable de données inédites.\n",
    "À condition bien sûr de savoir accéder aux données, les traiter et les analyser.\n",
    "\n",
    "Ce petit démonstrateur est une initiation aux méthodes de collecte, de traitement et d’analyse des données patrimoniales.\n",
    "\n",
    "Nous découvrirons :\n",
    "\n",
    "- les méthodes d’accès aux données via des APIs, avec la librairie Python `requests` ;\n",
    "- l’écosystème des données ouvertes partagées par la BnF, Gallica en particulier, et DBPedia ;\n",
    "- une méthode pour la reconnaissance et le liage des entités nommées (*Entity linking*) pour enrichir les données collectées ;\n",
    "- comment construire une chaîne de traitement complète de *geoparsing* dans des textes (issus de Gallica) ;\n",
    "- une méthode de visualisation (cartographique) des résultats ;\n",
    "- comment une carte de chaleur avec la bibliothèque `folium`.\n",
    "\n",
    "Ce faisant, vous comprendrez mieux le fonctionnement du Web (HTTP), découvrirez les formats de données structurés (CSV, JSON, XML) et aurez une expérience pratique du langage de programmation Python.\n",
    "\n",
    "Ce tutoriel reprend largement le cours de **Bertrand Dumenieu** (EHESS) dédié à l'expérimentation du traitement automatique du langage naturel (TALN) grâce à un modèle d'apprentissage profond. Un grand merci à lui pour le partage de ces éléments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f1bf4-3462-4363-9495-9d37117ef6be",
   "metadata": {},
   "source": [
    "## Automatiser la collecte de données\n",
    "\n",
    "### Gallica\n",
    "\n",
    "Librement accessible depuis 1997, [Gallica](https://gallica.bnf.fr/) est la bibliothèque numérique de la Bibliothèque nationale de France et de ses partenaires.\n",
    "\n",
    "- accès libre et gratuit à 10 millions de documents numérisés\n",
    "- de toutes époques et de tous supports (manuscrits, journaux, etc.)\n",
    "- une application de recherche et de consultation : [https://gallica.bnf.fr/accueil/fr/html/accueil-fr](https://gallica.bnf.fr/accueil/fr/html/accueil-fr)\n",
    "- des APIs : [https://api.bnf.fr/fr/recherche?q=recherche&f%5B0%5D=categories%3A4&f%5B1%5D=sources%3A197](https://api.bnf.fr/fr/recherche?q=recherche&f%5B0%5D=categories%3A4&f%5B1%5D=sources%3A197)\n",
    "\n",
    "Une API (*Application Programming Interface*) est un moyen pour des programmes informatiques de communiquer entre eux.\n",
    "Contrairement à une interface utilisateur, qui relie un ordinateur à une personne, une API relie des ordinateurs ou des logiciels entre eux. Elle n'est pas destinée à être utilisée directement par une personne (l'utilisateur final) autre qu'un programmeur informatique qui l'incorpore dans le logiciel.\n",
    "\n",
    "- Une API permet à un ordinateur de demander des informations à un autre ordinateur via l'internet.\n",
    "- Les points d'accès aux données et le format de la réponse sont normalisés conformément à une spécification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b567f-24eb-488d-b9c0-6c88bdd24476",
   "metadata": {},
   "source": [
    "### Gallica Search API (XML)\n",
    "\n",
    "\n",
    "La BnF a fait un travail impressionnant de mise à disposition de ces ressources ouvertes, via différentes API qui permettent d'interagir avec différents services : métadonnées, données textuelles, mais aussi recueil de données iconographiques.\n",
    "\n",
    "Ces [API de Gallica sont documentées](https://api.bnf.fr/recherche?f[0]=sources:197) de manière exemplaire, avec une attention particulière portée aux besoins des chercheurs.\n",
    "\n",
    "**L’API de recherche (SRU) permet d'effectuer des recherches dans la collection numérique de Gallica:**\n",
    "\n",
    "\n",
    "- **Documentation** : [https://api.bnf.fr/fr/api-gallica-de-recherche](https://api.bnf.fr/fr/api-gallica-de-recherche)\n",
    "- **Service de recherche Gallica SRU** : https://api.bnf.fr/fr/api-gallica-de-recherche#scroll-nav__3\n",
    "\n",
    "SRU (Search/Retrieval via URL) est un **protocole standard d'échange de métadonnées** adapté aux besoins des catalogues de bibliothèques. En d'autres termes, les bibliothèques ont collaboré pour définir un moyen normalisé d'exposer leur catalogue en tant que service web.\n",
    "\n",
    "La norme SRU spécifie **comment interroger** le serveur qui expose les données du catalogue et **comment formater la réponse**.\n",
    "\n",
    "Lire : https://bibliotheques.wordpress.com/2017/10/27/papa-cest-quoi-un-sru/\n",
    "\n",
    "**En utilisant l'API de recherche, commençons par essayer de collecter automatiquement les données relatives aux romans de Jules Verne.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8a4f6d-32e3-44f8-b87b-c3f5e3f12bcb",
   "metadata": {},
   "source": [
    "\n",
    "### CQL Query\n",
    "\n",
    "La base : `https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query={CQL_QUERY}`\n",
    "\n",
    "\n",
    "[CQL, Contextual Query Language](https://www.loc.gov/standards/sru/cql/), est un langage formel pour adresser des requêtes aux systèmes de recherche d'informations tels que les index Web, les catalogues bibliographiques et les informations sur les collections de musées. L'objectif de la conception est que les requêtes soient lisibles et facile à rédiger par l'homme, et que le langage soit intuitif tout en conservant l'expressivité de langages plus complexes.\n",
    "\n",
    "\n",
    "Quelques exemples pour vous aider à comprendre.\n",
    "\n",
    "\n",
    "**Les documents mentionnant \"Jules Verne\" dans Gallica** (>18752 records…):\n",
    "\n",
    "- `query=gallica all \"Jules Verne\"`\n",
    "- [https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&**query=gallica all \"Jules Verne\"**](https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query=gallica%20all%20%22Jules%20Verne%22)\n",
    "\n",
    "**Les documents dont \"Jules Verne\" est l’auteur dans Gallica** (>400 records):  \n",
    "\n",
    "- `query=dc.creator all \"jules verne\"`\n",
    "- [https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&**query=dc.creator all \"Jules Verne\"**](https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query=dc.creator%20all%20%22Jules%20Verne%22)\n",
    "\n",
    "**Les livres (monographs) en français dont \"Jules Verne\" est l’auteur dans Gallica** (>290 records):\n",
    "\n",
    "- `query=dc.creator all \"jules verne\"&filter=dc.type all \"monographie\" and dc.language all \"fre\"`\n",
    "- [https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&**query=dc.creator all \"jules verne\"&filter=dc.type all \"monographie\" and dc.language all \"fre\"**](https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query=dc.creator%20all%20%22jules%20verne%22&filter=dc.type%20all%20%22monographie%22%20and%20dc.language%20all%20%22fre%22)\n",
    "\n",
    "\n",
    "On peut **trier les résultats** selon différents critères.\n",
    "\n",
    "Les résultats peuvent être triés selon la qualité de l’OCR de la couche texte : `ocr.quality/sort.descending`:\n",
    "\n",
    "[https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query=dc.creator all \"jules verne\" sortby ocr.quality/sort.descending&filter=dc.type all \"monographie\" and dc.language all \"fre\"](https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query=dc.creator%20all%20%22jules%20verne%22%20sortby%20ocr.quality/sort.descending&filter=dc.type%20all%20%22monographie%22%20and%20dc.language%20all%20%22fre%22)\n",
    "\n",
    "Il existe de nombreux autres paramètres :\n",
    " \n",
    "- `startRecord` : l'indice du système de pagination, entre 1 et le nombre maximum de résultats retournés par la requête\n",
    "- `maximumRecords` : le nombre de résultats retournés par le service (de 0 à un maximum de 50). Par défaut, si ce paramètre n'est pas présent, la valeur est de 15.\n",
    "\n",
    "\n",
    "**Dans Gallica, 3 (`&maximumRecords=3`) monographies (`dc.type all \"monographie\"`) en français (`dc.language all \"fre\"`) de 1966 (`dc.date=\"1966\"`) mentionnant le \"Festival Mondial des Arts Nègres\"** :\n",
    "\n",
    "- `query=gallica all \"Festival Mondial des Arts Nègres\" sortby ocr.quality/sort.descending&filter=dc.type all \"monographie\" and dc.language all \"fre\" and dc.date=\"1966\"&maximumRecords=3`\n",
    "- [https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query=gallica all \"Festival Mondial des Arts Nègres\" sortby ocr.quality/sort.descending&filter=dc.type all \"monographie\" and dc.language all \"fre\" and dc.date=\"1966\"&maximumRecords=3](https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query=gallica%20all%20%22Festival%20Mondial%20des%20Arts%20N%C3%A8gres%22%20sortby%20ocr.quality/sort.descending&filter=dc.type%20all%20%22monographie%22%20and%20dc.language%20all%20%22fre%22%20and%20dc.date=%221966%22&maximumRecords=3)\n",
    "\n",
    "Dans Gallica, les revues (`dc.type all \"fascicule\"`) en français postérieures à 1976 (`dc.date >= \"1976\"`) mentionnant le \"FESTAC\" :\n",
    "\n",
    "\n",
    "- `&query=gallica all \"FESTAC\" sortby ocr.quality/sort.descending&filter=dc.type all \"fascicule\" and dc.language all \"fre\" and dc.date >= \"1976\"`\n",
    "- [https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query=gallica all \"FESTAC\" sortby ocr.quality/sort.descending&filter=dc.type all \"fascicule\" and dc.language all \"fre\" and dc.date >= \"1976\"](https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query=gallica%20all%20%22FESTAC%22%20sortby%20ocr.quality/sort.descending&filter=dc.type%20all%20%22fascicule%22%20and%20dc.language%20all%20%22fre%22%20and%20dc.date%20%3E=%20%221976%22)\n",
    "\n",
    "Dans le cas des revues, on obtient l’ARK de la revue et non directement celui de la publication contenant l’expression recherchée…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c79c1-0d94-4c71-858c-5811f18077ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "TROUVER AUTRE EX\n",
    "url = 'https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query=gallica%20all%20%22FESTAC%22%20sortby%20ocr.quality/sort.descending&filter=dc.type%20all%20%22fascicule%22%20and%20dc.language%20all%20%22fre%22%20and%20dc.date%20%3E=%20%221976%22'\n",
    "response = requests.get(url)\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e2597-621a-49e1-a5eb-282bae4e90e9",
   "metadata": {},
   "source": [
    "### Requêtes et réponses HTTP (requests)\n",
    "\n",
    "Pour accéder par programme aux données textuelles attachées à chaque URL, nous pouvons utiliser une bibliothèque Python appelée [requests](https://requests.readthedocs.io/en/master/).\n",
    "\n",
    "Une ULR ([Uniform Resource Locator](https://en.wikipedia.org/wiki/URL))est une référence à une ressource web qui spécifie son emplacement sur un réseau informatique et un mécanisme pour la récupérer.\n",
    "\n",
    "Chaque URL HTTP est conforme à la syntaxe d'un URI générique. La syntaxe générique de l'URI se compose de 6 éléments organisés hiérarchiquement :\n",
    "\n",
    "`http://www.domain.com:80/path/to/myfile.html?key1=value1&key2=value2#anchor_in_doc`\n",
    "\n",
    "URLS parts:\n",
    "\n",
    "- **protocol**: `http://` or `https://`.\n",
    "- **domain name**: `www.domain.com` – au lieu d'un nom de domaine, vous pouvez utiliser une adresse IP.\n",
    "- **port**: `:80` - indique la \"porte\" technique à utiliser pour accéder aux ressources du serveur. Ce fragment est généralement absent, car le navigateur utilise les ports standards associés aux protocoles (80 pour HTTP, 443 pour HTTPS).\n",
    "- **path**: `/path/to/myfile.html` –chemin, sur le serveur web, vers la ressource. Dans les premiers temps du Web, ce chemin correspondait souvent à un chemin « physique » existant sur le serveur. Aujourd'hui, ce chemin n'est qu'une abstraction gérée par le serveur web, et ne correspond plus à une réalité \"physique\".\n",
    "- **parameters**: `?key1=value1&key2=value2` – construit comme une liste de paires clé/valeur séparées par une esperluette.\n",
    "- **anchor**: `#anchor_in_doc` – pointe vers un endroit donné de la ressource.\n",
    "\n",
    "Lorsque vous tapez une URL dans la barre d'adresse de votre navigateur, vous envoyez une **demande** HTTP pour une page web, et le serveur qui stocke cette page web renverra une **réponse**.\n",
    "\n",
    "<img src=\"./img/http.png\" width=\"600px\">\n",
    "\n",
    "\n",
    "Une requête HTTP dont les paramètres sont passés via l'URL est dite de type GET.\n",
    "\n",
    "Avec le librairie requests, on peut très facilement exécuter ce genre de requêtes et récupérer une réponse grâce à la fonction `requests.get(...)` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f854e9dc-1752-482e-a480-9c3c8dd9daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query=dc.creator%20all%20%22jules%20verne%22%20sortby%20ocr.quality/sort.descending&filter=dc.type%20all%20%22monographie%22%20and%20dc.language%20all%20%22fre%22&maximumRecords=5\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status() # Appeler raise_for_status() après une requête GET est une bonne pratique : cela permet de lever automatiquement une exception si la requête a échoué.\n",
    "print(type(response), response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819a5122-176f-4545-b7ba-76fbb6b67e3b",
   "metadata": {},
   "source": [
    "`requests.get()` renvoie donc un objet Python de type `requests.models.Response`, qui quand on l'affiche donne le code HTTP retour, ici 200, qui signifie que [tout s'est bien passé ](https://developer.mozilla.org/fr/docs/Web/HTTP/Reference/Status/200).\n",
    "\n",
    "On peut alors récupérer le contenu de la réponse de plusieurs manières :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11f891-0cb2-4683-b8ac-67b54dccc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.headers['Content-Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da1d1f8-eb77-4365-89df-6f7acb5be625",
   "metadata": {},
   "source": [
    "Pour accéder à l’information et l’extraire nous avons besoin de ***parser* la donnée formatée en XML**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f345571-cd2b-42a9-906e-6cf547a277c3",
   "metadata": {},
   "source": [
    "**[The ElementTree XML API](https://docs.python.org/3/library/xml.etree.elementtree.html)**. Le module `xml.etree.ElementTree` (`ET` en abrégé) implémente une API simple et efficace pour l'analyse et la création de données XML.\n",
    "\n",
    "XML est un format de données hiérarchique, et la manière la plus intuitive de le représenter est un arbre. **ET dispose de deux classes** à cet effet :\n",
    "\n",
    "- `ElementTree` représente l'ensemble du document XML sous forme d'arbre\n",
    "- `Element` représente un nœud unique dans cet arbre.\n",
    "\n",
    "Les interactions avec l'ensemble du document (lecture et écriture dans les fichiers) se font généralement au niveau de l'`ElementTree`. Les interactions avec un seul élément XML et ses sous-éléments se font au niveau de l'`Element`.\n",
    "\n",
    "**[fromstring() analyse le XML à partir d'une chaîne directement dans un `Element`](https://docs.python.org/3/library/xml.etree.elementtree.html#xml.etree.ElementTree.fromstring)** - stocké ci-dessous dans la variable `root` qui est l'élément racine de l'arbre analysé.\n",
    "\n",
    "Ensuite, `Element` a quelques méthodes utiles qui aident à itérer récursivement sur tous les sous-arbres en dessous de lui (ses enfants, leurs enfants, et ainsi de suite). Par exemple, `Element.iter()`.\n",
    "\n",
    "**[La méthode iter()](https://docs.python.org/3/library/xml.etree.elementtree.html#xml.etree.ElementTree.Element.iter)** crée un itérateur d'arbre avec l'élément courant comme racine. L'itérateur parcourt cet élément et tous les éléments situés en dessous, dans l'ordre du document (profondeur en premier).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c73cce-47f5-44f6-a64d-d07f1a369861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "root = ET.fromstring(response.content)\n",
    "for child in root.iter('*'):\n",
    "    print(child.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443d8140-d05f-4366-8b67-b3446edf17f4",
   "metadata": {},
   "source": [
    "### Extraction des métadonnées (Search API)\n",
    "\n",
    "Nous voyons que tous les éléments de la réponse sont accessibles, selon leur espace de noms : `{http://purl.org/dc/elements/1.1/}creator` \n",
    "L'élément `creator` est déclaré pour l'espace de nom Dublin Core (`http://purl.org/dc/elements/1.1/`).\n",
    "\n",
    "En utilisant une boucle `for`, chaque `record` est lu, et la méthode `Element.findall()` est utilisée pour extraire les métadonnées du Dublin Core :\n",
    "\n",
    "- `identifier`\n",
    "- `date`\n",
    "- `title`\n",
    "- `creator`\n",
    "\n",
    "NB. La méthode [`Element.findall()`](https://docs.python.org/3/library/xml.etree.elementtree.html#xml.etree.ElementTree.Element.findall) ne trouve que les éléments avec une balise qui sont des enfants directs de l'élément courant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02521b-ae35-44aa-8852-c2cb51aa1755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_gallica_metadata(search_api_url, dc_elements_array):\n",
    "    response = requests.get(search_api_url)\n",
    "    root = ET.fromstring(response.content)\n",
    "    metadata = []\n",
    "    for record in root.iter('{http://www.loc.gov/zing/srw/}record'):\n",
    "        record_meta_dic = {}\n",
    "        for dc_el in dc_elements_array:\n",
    "            if record.findall('{http://www.loc.gov/zing/srw/}recordData/{http://www.openarchives.org/OAI/2.0/oai_dc/}dc/{http://purl.org/dc/elements/1.1/}'+dc_el):\n",
    "                record_meta_dic[dc_el] = record.findall('{http://www.loc.gov/zing/srw/}recordData/{http://www.openarchives.org/OAI/2.0/oai_dc/}dc/{http://purl.org/dc/elements/1.1/}'+dc_el)[0].text\n",
    "            else :\n",
    "                record_meta_dic[dc_el] = 'NaN'\n",
    "        # non DC metadata\n",
    "        record_meta_dic['ocr_quality'] = record.findall('{http://www.loc.gov/zing/srw/}extraRecordData/nqamoyen')[0].text if record.findall('{http://www.loc.gov/zing/srw/}extraRecordData/nqamoyen')[0].text else 'NaN'\n",
    "        metadata.append(record_meta_dic)\n",
    "    metadata_df = pd.DataFrame(metadata)\n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225fa18d-b1fe-4aa0-8a72-00fd18102338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query=dc.creator%20all%20%22jules%20verne%22%20sortby%20ocr.quality/sort.descending&filter=dc.type%20all%20%22monographie%22%20and%20dc.language%20all%20%22fre%22&startRecord=1&maximumRecords=5\"\n",
    "books_df = get_gallica_metadata(url, ['creator', 'identifier', 'title'])\n",
    "books_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9777fa2c-41f1-43f3-85dc-8a022359fe83",
   "metadata": {},
   "source": [
    "### Extraction du plein texte (Document API)\n",
    "\n",
    "Documentation : https://api.bnf.fr/fr/api-document-de-gallica\n",
    "\n",
    "Pour document trouvé via l'API de recherche ou l'interface Gallica, l'API Document peut être utilisée pour récupérer les métadonnées nécessaires à l'utilisation des ressources numériques du document, y compris :\n",
    "\n",
    "- les informations bibliographiques\n",
    "- les résultats de recherche\n",
    "- **le texte (texte brut / OCR)**\n",
    "\n",
    "Ainsi, pour un identifiant ark, si le document a été \"OCRisé\", il est toujours possible de récupérer tout le texte.\n",
    "\n",
    "C'est vraiment très simple !\n",
    "\n",
    "Lorsqu'un document est indexé en texte intégral, il est possible d'obtenir ce texte en utilisant le qualificateur `textBrut` :  \n",
    "https://gallica.bnf.fr/{ark}.texteBrut\n",
    "\n",
    "Pour l’exemple, nous travaillerons sur l’édition française du Bulletin d'information du Conseil international des musées (parution de décembre 1964), première mention du Festival mondial des arts nègres :  \n",
    "https://gallica.bnf.fr/ark:/12148/bpt6k65591428\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c76679-3568-4457-9a1c-5b9d2855f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ark_url = 'https://gallica.bnf.fr/ark:/12148/bpt6k65591428'\n",
    "text_url = f\"{ark_url}.texteBrut\"\n",
    "response = requests.get(text_url)\n",
    "print(response.text[0:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f9be8e-0f3d-4fc9-a643-945be4a3b81a",
   "metadata": {},
   "source": [
    "Que trouve-t-on ? Étonnamment, le texte n’est pas réellement disponible en texte brut, mais est formaté en HTML…\n",
    "On pourrait se contenter de supprimer les balises. Mais il y a mieux à faire.\n",
    "\n",
    "En examinant attentivement le document on s’aperçoit que le texte débute après la première balise HTML `<hr/>`.  \n",
    "Grâce à la librairie [BeautifulSoup](https://pypi.org/project/beautifulsoup4/), nous pouvons extraire le seul texte du document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd3b72-d833-4b05-a6d8-5bdb11b93210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0894d282-efd4-49c5-8583-b7beda97f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_text(ark_url):\n",
    "    response = requests.get(ark_url+'.texteBrut')\n",
    "    document = BeautifulSoup(response.text, \"html.parser\")\n",
    "    first_hr_tag = document.select('hr')[0]\n",
    "    text = ''\n",
    "    for p in first_hr_tag.find_all_next('p'):\n",
    "        text += p.text + '\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727537c1-a68a-4718-be4e-4fe8009b7f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_doc_text(ark_url)[0:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f76089-2381-48c3-acc0-bdb0c8d9a214",
   "metadata": {},
   "source": [
    "### Enregistrer le texte dans un fichier\n",
    "\n",
    "Si on souhaitera le plus souvent stocker les données dans un Dataframe, on a souvent besoin d’enregistrer les données en local…\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3079e62-bed6-4de5-8bfd-2c6853b42d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = ark_url[34:] # on ne retient que le suffixe de l’ark pour le nom du fichier\n",
    "with open(f'docs/{file_name}.txt', 'a') as file:\n",
    "    file.write(get_doc_text(ark_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2bdb3-b32c-49db-bb4a-55360a77bf41",
   "metadata": {},
   "source": [
    "**Pour nous prémunir des problèmes de réseau, nous allons travailler avec ce même document enregistré : `./docs/bpt6k65591428`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0d7b10-1da8-483d-a2fa-fc742103824d",
   "metadata": {},
   "source": [
    "## Reconnaissance des entités nommées avec spaCy\n",
    "\n",
    "SpaCy est une bibliothèque logicielle Python pour le traitement automatique de nombreuses langues. Il s'agit d'une boîte à outils essentielle pour l'analyse computationnelle de corpus de textes.\n",
    "\n",
    "À lire :\n",
    "\n",
    "- https://spacy.io/\n",
    "- Avanced NLP with Spacy : https://course.spacy.io/en/\n",
    "- https://github.com/mchesterkadwell/named-entity-recognition/blob/main/1-basic-text-mining-concepts.ipynb\n",
    "- for NER : https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/12-Named-Entity-Recognition.html\n",
    "- for Text-Mining (basics) : https://github.com/mchesterkadwell/named-entity-recognition/blob/main/1-basic-text-mining-concepts.ipynb \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82be85-2eeb-41f7-87b0-b4d0df92bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import Spacy\n",
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f86b1-d95b-44bb-b37b-a418cf64d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9785bdc8-899d-4221-8be0-ee8cef1bcf54",
   "metadata": {},
   "source": [
    "### Pipelines de traitement du langage et modèles entraînés\n",
    "\n",
    "[https://spacy.io/usage/processing-pipelines](https://spacy.io/usage/processing-pipelines)\n",
    "\n",
    "Lorsque vous appelez nlp sur un texte, spaCy commence par tokeniser le texte pour produire un [objet Doc](https://spacy.io/api/doc). Le document est ensuite traité en plusieurs étapes (c'est-à-dire le pipeline de traitement). Chaque composant du pipeline renvoie le document traité, qui est ensuite transmis au composant suivant.\n",
    "\n",
    "![spacy_pipeline](img/spacy_pipeline.svg)\n",
    "\n",
    "Les capacités d'un pipeline de traitement dépendent toujours des composants, de leurs modèles et de la manière dont ils ont été formés. Par exemple, un pipeline de reconnaissance d'entités nommées doit inclure un composant de reconnaissance d'entités nommées formé.\n",
    "\n",
    "Il convient de se référer à la documentation des modèles mis à disposition : [https://spacy.io/models](https://spacy.io/models)\n",
    "\n",
    "#### Installation et importation d'un pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa8ece-1542-44d4-a2de-1376eb3aec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge spacy-model-fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dbb0d3-d648-49cd-b7f4-c01956979084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fr_core_news_md\n",
    "nlp = fr_core_news_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d893f-a784-45f0-8656-826174a5d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808be01d-7a8e-4440-846d-c832fa009196",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ed762-b696-42b2-899b-ee342ce4564d",
   "metadata": {},
   "source": [
    "### Reconnaissance des entités nommées¶\n",
    "\n",
    "La reconnaissance des entités nommées (NER) est le processus qui consiste à localiser les entités nommées et à les classer dans des catégories prédéfinies, telles que les noms de personnes, les lieux, les organisations.\n",
    "\n",
    "spaCy possède la propriété .ents sur les objets Doc. Vous pouvez l'utiliser pour extraire des entités nommées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7722e197-e65c-4692-a9f8-d54acb75f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from spacy import displacy\n",
    "\n",
    "with open(\"docs/bpt6k65591428.txt\", \"r\") as file:\n",
    "    texte = file.read()\n",
    "\n",
    "doc = nlp(texte)\n",
    "# ⚠️ ATTENTION, la sortie de la cellule suivante est très longue, n'hésitez pas à commenter la ligne suivante une fois que vous avez vu le résultat\n",
    "display.HTML(displacy.render(doc, style=\"ent\", jupyter=False, page=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eab34e-4c97-4413-b09c-4f73e5df4dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docs/bpt6k65591428.txt\", \"r\") as file:\n",
    "    texte = file.read()\n",
    "\n",
    "doc = nlp(texte)\n",
    "\n",
    "for ent in doc[3500:3550].ents:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "        {ent.text = }\n",
    "        {ent.label_ = }\n",
    "        type = {spacy.explain(ent.label_)}\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e320ae-0f90-4b43-9189-a87500c1c4ff",
   "metadata": {},
   "source": [
    "Dans l'exemple ci-dessus, `ent` est un [Span object] (https://spacy.io/api/span) avec divers attributs :\n",
    "\n",
    "- `.text` donne la représentation textuelle Unicode (la chaîne) de l'entité.\n",
    "- `.label_` donne l'étiquette de l'entité.\n",
    "- `.start_char` indique le décalage de caractère pour le début de l'entité.\n",
    "- `.end_char` indique le décalage de caractère pour la fin de l'entité.\n",
    "\n",
    "`spacy.explain()` donne des détails descriptifs sur chaque étiquette d'entité."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0249691e-6106-4a46-a2bc-8c5c3818eeaf",
   "metadata": {},
   "source": [
    "Comptage des lieux : pour une meilleure compréhension, nous proposons 2 méthodes :\n",
    "\n",
    "- La première avec une boucle `for`, pour comprendre comment lire la liste des entités.\n",
    "- La seconde (List comprehension) est plus \"pythonique\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b9b7af-db2e-4e48-844f-d4fa3aa204b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# method 1:\n",
    "places = []\n",
    "for named_entity in doc.ents:\n",
    "    if named_entity.label_ == \"LOC\":\n",
    "        places.append(named_entity.text)\n",
    "\n",
    "print(Counter(places).most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ab0b2-c375-45ab-8b22-73e9fec9470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2 (pythonic):\n",
    "places = [\n",
    "    entity.text\n",
    "    for entity in doc.ents\n",
    "    if entity.label_ == 'LOC'\n",
    "]\n",
    "places_df = pd.DataFrame(Counter(places).most_common(20), columns=['place', 'count'])\n",
    "places_df.iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c661e831-ae60-44b2-b757-baff86f07f3e",
   "metadata": {},
   "source": [
    "Vous pouvez également utiliser displaCy pour visualiser ces entités. Ici, nous ne visualisons que quelques phrases (`list(doc.sents)[n:m]`), mais il est bien sûr possible d'annoter le texte entier (`doc`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312934c8-2c58-406f-a85d-372a1c85e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(list(doc.sents)[1000:1100], style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6feb248-2336-4cbf-8f7c-5cdbf1b19a19",
   "metadata": {},
   "source": [
    "On constate surtout que le modèle est assez mauvais par défaut. Plusieurs raisons\n",
    "\n",
    "Pour l’exercice nous avons préparé un modèle plus efficace (voir `ner/model-best`).\n",
    "\n",
    "Pour comprendre comment ce modèle a été entraîné (avec les données partagées par le BnF), lire le [cours de Bertrand Duménieu](https://github.com/HueyNemud/enc-tnah-atelierspython-nlp/tree/main/partie_1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc76d7-b74f-4005-a46e-b90b2ddc049f",
   "metadata": {},
   "source": [
    "<style>\n",
    "    .renbox {\n",
    "        width: 100%;\n",
    "        height: 100%;\n",
    "        padding: 2px;\n",
    "        margin: 3px;\n",
    "        border-radius: 3px;\n",
    "        box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
    "        font-weight: bolder;\n",
    "        background-color: #8b8c8b;\n",
    "    }\n",
    "    .per {\n",
    "        background-color: #ffb654;\n",
    "    }\n",
    "    .org {\n",
    "        background-color: #49ace6;\n",
    "    }\n",
    "    .misc {\n",
    "        background-color: #c2ccd1;\n",
    "    }\n",
    "    .loc {\n",
    "        background-color: #3deb6c;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "\n",
    "## Résolution de toponymes et géocodage avec DBPedia\n",
    "\n",
    "### Introduction à la résolution de toponymes 🔬\n",
    "\n",
    "La **résolution de toponymes** entre dans le domaine de l'ingénierie des connaissances en tant que cas particulier d'une tâche générale nommée **liage d'entités** (en anglais *Entity Linking - EL*).\n",
    "Le liage d'entités suit l'étape de reconnaissance des entités nommées (REN/*NER*) et consiste à associer les entités annotées avec une **ressource dans une base de connaissances de référence** avec deux objectifs :\n",
    "\n",
    "1. **désambiguïser** les entités nommées, car on considère que deux entités nommées liées à la même ressource sont en fait deux mentions de la même entité du monde réel.\n",
    "2. **enrichir** les informations extraites grâce aux métadonnées que fournit la base de connaissances. Dans le cas des lieux, on sera évidemment intéressé par leurs **coordonnées géographiques**.\n",
    "\n",
    "La résolution de toponymes est tout simplement le nom donné au liage d'entités nommées qui désignent des lieux. Si, en plus, on récupère des coordonnées géographiques pour cartographier les toponymes, la tâche devient une tâche de **géocodage** !\n",
    "\n",
    "La base de connaissance peut être n'importe quel référentiel externe, mais les **bonnes pratiques** du domaine veulent que l'on essaye généralement de privilégier soit des **référentiels d'autorité** comme le catalogue de la BnF, soit des grands **graphes de connaissances ouverts** et publiés sur le Web de données, par exemple Wikidata ou DBPedia qui sont des versions de Wikipedia sous forme de graphes de connaissances.\n",
    "\n",
    "Le processus de résolution de toponymes peut être décomposé en trois parties  :\n",
    "\n",
    "<img src=\"./img/schema.jpg\" alt=\"Recherche dans un référentiel -> Désambiguisation -> Géocodage\" width=\"80%\"></img>\n",
    "\n",
    "<span style=\"color: red; font-size: 1.2em;\"><strong>🚨 Attention |</strong></span>  **Dans cet atelier nous négligeront l'étape de désambiguïsation.* Elle peut toutefois être essentielle selon le cas d'application.\n",
    "\n",
    "### Échauffement\n",
    "\n",
    "Commençons par la première étape de **recherche des entités nommées lieux (LOC)**.\n",
    "\n",
    "Pour l'exemple, dans  l'extrait de l'article sur le naufrage du titanic on trouve deux mentions de lieux, <span class =\"renbox loc\">Staffordshire<sup>[LIEU]</sup></span> et <span class =\"renbox loc\">Liverpool<sup>[LIEU]</sup></span> : \n",
    "\n",
    "\n",
    "> « Le capitaine <span class =\"renbox per\">Smith<sup>[PERSONNE]</sup></span> qui commandait le <span class=\"renbox misc\">Titanic<sup>[OBJET]</sup></span> est, nous l'avons dit hier, depuis plus de 35 ans au service de la <span class =\"renbox org\">White Star Line<sup>[ORGANISATION]</sup></span>.\n",
    "> Il est actuellement agé de 60 ans.\n",
    ">  Né dans le <span class =\"renbox loc\">Staffordshire<sup>[LIEU]</sup></span>, le capitaine <span class =\"renbox per\">Smith<sup>[PERSONNE]</sup></span> avait fait son apprentissage de marin dans la maison d'armement <span class =\"renbox org\">Gibson et C°<sup>[ORGANISATION]</sup></span>, de <span class =\"renbox loc\">Liverpool<sup>[LIEU]</sup></span>. »\n",
    "\n",
    "\n",
    "Nous allons utiliser comme référentiel de [DBPediaFR](https://fr.dbpedia.org/) (https://fr.dbpedia.org/).\n",
    "DBPediaFR est une représentation en graphe de connaissances du contenu de Wikipédia en français. \n",
    "\n",
    "Chaque page de Wikipédia en français devient donc une **ressource RDF** dans le graphe, qui possède une **URI** et qui est enrichie de nombreuses **métadonnées**.\n",
    "\n",
    "Par exemple, la page Wikipédia de l'École Nationale des Chartes est transformée une ressources RDF dont l'URI (qui est ici un URL) est :\n",
    "> http://fr.dbpedia.org/resource/École_nationale_des_chartes\n",
    "\n",
    "Si l'on va à cet URL dans un navigateur Web, on peut voir un résumé de toutes les triplets RDF associés à cette ressource.\n",
    "\n",
    "Mais comment trouve-t-on l'URI d'un lieu dans DBPediaFR à partir de son nom ?\n",
    "Pour cela, on peut utiliser l'outil open source  [https://fr.dbpedia.org/lookup.html](https://fr.dbpedia.org/lookup.html), qui permet justement de faire cette recherche ! \n",
    "\n",
    "<div style=\"border-top: 1px solid #ff9800; padding: 10px; border-radius: 5px; color:#ff9800;\"><strong>🧩 - QUESTION 1 - ⭐</strong></div>\n",
    "\n",
    "En utilisant l'outil DBPediaFR lookup (https://fr.dbpedia.org/lookup.html), recherchez le lieu <span class =\"renbox loc\">Staffordshire<sup>[LIEU]</sup></span>.\n",
    "Rendez-vous sur la page de présentation de la meilleure resource identifiée, et recherchez parmi les triplets associés s'il y a des coordonnées géographiques. \n",
    "\n",
    "Quel sont les noms et les préfixes RDF des propriétés utilisées pour décrire ces informations géographiques ? Notez les dans un coin, vous en aurez besoin plus tard !\n",
    "\n",
    "<div style=\"border-bottom: 1px solid #ff9800; padding: 10px; border-radius: 5px; margin-top: -30px;\"></div>\n",
    "\n",
    "Vous venez de tester à la main la première étape de la  résolution de toponymes grâce à DBPedia Lookup.\n",
    "Le but va maintenant être d'automatiser ce processus !\n",
    "\n",
    "\n",
    "### Résoudre un toponyme avec l'API de DBPedia Lookup\n",
    "\n",
    "[DPBedia Lookpup](https://github.com/dbpedia/dbpedia-lookup) va être très utile car son instance officielle [https://lookup.dbpedia.org/](https://fr.dbpedia.org/lookup.html) mets à disposition une API REST qui permet de l'interroger avec une simple URL.\n",
    "\n",
    "Par exemple pour récupérer les meilleurs candidats pour le toponym *Staffordshire*, il suffit d'appeler : \n",
    "\n",
    "\n",
    ">https://fr.dbpedia.org/lookup/api/search?query=Staffordshire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766a9da-c76b-45d6-8760-a1dfdbfa1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "! curl -s \"https://fr.dbpedia.org/lookup/api/search?query=Staffordshire\" # -s pour le mode silencieux et ne pas afficher la progression de la requête"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131f0101-af35-42f7-a746-b9fe6f223de9",
   "metadata": {},
   "source": [
    "<span style=\"color: #40d6d1; font-size: 1.2em;\"><strong>💡 Astuce |</strong></span> Une documentation est disponible ici : https://www.dbpedia.org/resources/lookup/\n",
    "\n",
    "Vous aurez remarqué qu'on récupère les résultats au format XML, peu pratique à manipuler en Python.\n",
    "Heureusement l'outil propose un mécanisme de **négociation de contenu** qui permet de préciser un format alternatif avec le paramètre `format=`...et il serait préférable de récupérer du JSON.\n",
    "\n",
    "<div style=\"border-top: 1px solid #ff9800; padding: 10px; border-radius: 5px; color:#ff9800;\"><strong>🧩 - QUESTION 2 - </strong></div>\n",
    "\n",
    "Dans votre navigateur Web préféré, allez à l'URL suivante et vérifiez si les résultats renvoyés par l'API semblent correspondre à ce que vous obteniez avec la version graphique de DBPediaFR Lookup :\n",
    "\n",
    "> https://fr.dbpedia.org/lookup/api/search?query=Staffordshire&format=JSON\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651fb0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "! curl -s \"https://fr.dbpedia.org/lookup/api/search?query=Staffordshire&format=JSON\" # -s pour le mode silencieux et ne pas afficher la progression de la requête"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaac9b0-b4ca-4378-aad7-7d3fc7ab2c23",
   "metadata": {},
   "source": [
    "\n",
    " <div style=\"border-bottom: 1px solid #ff9800; padding: 10px; border-radius: 5px; margin-top: -30px;\"></div>\n",
    "\n",
    "### Automatisation des appels à DBPedia Lookup\n",
    "\n",
    "Bien sûr, on souhaite automatiser ces appels à l'API afin de pouvoir résoudre des toponymes reconnus dans un texte à la volée !\n",
    "\n",
    "Maintenant, vous connaissez la bibliothèque `requests` !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6cb87d-3c6c-48d8-a601-f208891017b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc38b75-1536-434a-82c5-02f4f9291b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"https://fr.dbpedia.org/lookup/api/search?query=Staffordshire&format=JSON\"\n",
    "response = requests.get(url)\n",
    "#response.headers['Content-Type']\n",
    "response.raise_for_status() # Appeler raise_for_status() après une requête GET est une bonne pratique : cela permet de lever automatiquement une exception si la requête a échoué.\n",
    "print(type(response), response, response.headers['Content-Type'], response.text)\n",
    "#print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ee551c-81aa-4a7d-90be-53e71293534c",
   "metadata": {},
   "source": [
    "La fonction `dbpedia_lookup(toponyme: str)` ci-dessous prend en paramètre un `toponyme` sous forme de chaîne de caractère, et renvoie  le contenu de l'élément racine \"docs\" de la réponse HTTP sous forme d'une liste de ressources représentées par des dictionnaires Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0860a1b2-af74-4392-91b9-3ef35d9420bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complétez-moi ! 🏗️\n",
    "\n",
    "from typing import Any\n",
    "from functools import cache\n",
    "\n",
    "\n",
    "@cache\n",
    "def dbpedia_lookup(toponyme: str) -> list[dict[str, Any]]:\n",
    "    query = f\"https://fr.dbpedia.org/lookup/api/search?query={toponyme}&format=JSON\"\n",
    "    response = requests.get(query)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    response_json = response.json()\n",
    "    docs = response_json.get(\"docs\")\n",
    "    return docs or []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd225299-c078-49dd-9052-edf56514cd29",
   "metadata": {},
   "source": [
    "### Récupération de l'URI de la meilleure resource identifiée\n",
    "\n",
    "DBPediaFR nous renvoie la liste des resources correspondant à la requête. C'est bien, mais ce que l'on aimerait c'est accéder aux triplets associés à cette resource afin de récupérer les coordonnées géographiques associées, s'il y en a !\n",
    "\n",
    "Nous allons donc avoir besoin d'un mécanisme supplémentaire pour :\n",
    "1. **récupérer** les URI des resources dans les dictionnaires renvoyés par `dbpedia_lookup()`.\n",
    "2. **filtrer la liste** pour conserver uniquement le meilleur résultat (=le premier) pour éviter des requêtes sur des resources que l'on utilisera pas.\n",
    "\n",
    "\n",
    "Nous allons pour cela créer une nouvelle fonction qui englobera `dbpedia_lookup()`, nommées `dbpedia_top1(toponyme: str)-> str | None` qui prends en paramètre un toponyme et renvoie **l'URI de la meilleure resource identifiée par DBPediaFR lookup** (ou None s'il n'y a pas de résultat).\n",
    "\n",
    "\n",
    "Chaque resources JSON renvoyée par l'API de DBPediaFR Lookup contient une propriété `resource` contenant une liste d'URI pour cette resource.\n",
    "Nous considérerons que l'URI de la resource est **le premier élément de cette liste**.\n",
    "\n",
    "Par exemple, ce sera \"http://dbpedia.org/resource/Staffordshire\" pour le toponyme \"Staffordshire\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66879c6-c9c6-43b8-8dc5-296566cc730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "! curl -s \"https://fr.dbpedia.org/lookup/api/search?query=Staffordshire&format=JSON\" | jq \".docs[0].resource\" # jq est un utilitaire bash pour manipuler du JSON, très très pratique !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3dfee3-aadb-466b-a895-a41f5e8988a2",
   "metadata": {},
   "source": [
    "La fonction `dbpedia_top1(str)` dans la cellule suivante récupère **l'URI de la meilleure resources trouvées pour un toponyme passé en argument**.\n",
    "Si aucun résultat n'est trouvé, la fonction doit renvoyer None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42f17c-5a99-4e78-adc8-0ab533d76c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "\n",
    "\n",
    "@cache  # On active la mise en cache pour cette fonction, cf. l'astuce précédente\n",
    "def dbpedia_top1(toponyme: str) -> str | None:\n",
    "    r = dbpedia_lookup(toponyme)\n",
    "    if not r:\n",
    "        return None\n",
    "    else:\n",
    "        return r[0].get(\"resource\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8221e6-c2c3-41d2-b4a0-e657b2f9e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "t = \"Staffordshire\"\n",
    "r = dbpedia_top1(t)\n",
    "\n",
    "# La réponse doit être l'URI attendue, sous forme de chaîne de caractères\n",
    "assert [isinstance(r, str), r == \"http://f.dbpedia.org/resource/Staffordshire\"]\n",
    "\n",
    "t = \"Cette ressource n'existe pas \"\n",
    "r = dbpedia_top1(t)\n",
    "\n",
    "# Une resource inexistante doit retourner None, pas provoquer d'erreur\n",
    "assert r is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0360ea18-f91d-4ddd-9bb9-4485bc76b275",
   "metadata": {},
   "source": [
    "<div style=\"border-top: 1px solid #ff9800; padding: 10px; border-radius: 5px; color:#ff9800;\"><strong>🧩 - QUESTION 5 - </strong></div>\n",
    "\n",
    "Exécutez cette requête dans le *SPARQL endpoint* de DBPediaFR (https://fr.dbpedia.org/sparql) et vérifiez le résultat contient bien les latitude et longitude du Staffordshire.\n",
    "\n",
    "<pre>\n",
    "PREFIX geo: <http://www.w3.org/2003/01/geo/wgs84_pos#>\n",
    "SELECT ?lat ?long\n",
    "WHERE {<http://fr.dbpedia.org/resource/Staffordshire> (geo:lat) ?lat ; (geo:long) ?long.}\n",
    "</pre>\n",
    "\n",
    "<span style=\"color: #40d6d1; font-size: 1.2em;\"><strong>💡 Astuce |</strong></span> Ces coordonnées sont celles d'un point, alors que Stafforshire est un comté; c'est donc une description géographique grossière d'une entité surfacique, sans doute son centroïde. Vous pouvez d'ailleurs copier ces coordonnées dans [Google Maps](https://www.google.fr/maps) pour voir quel emplacement sur Terre elles désignent.\n",
    "\n",
    " <div style=\"border-bottom: 1px solid #ff9800; padding: 10px; border-radius: 5px; margin-top: -30px;\"></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec1074-846a-4a6b-95b2-6bcc99a6eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "! curl -s -X POST \\\n",
    "-H \"Content-Type: application/sparql-query\" \\\n",
    "-H \"Accept: application/json\" \\\n",
    "--data '''PREFIX geo: <http://www.w3.org/2003/01/geo/wgs84_pos#> SELECT ?lat ?long WHERE { <http://fr.dbpedia.org/resource/Staffordshire> (geo:lat) ?lat ; (geo:long) ?long. }''' \\\n",
    "  http://fr.dbpedia.org/sparql \\\n",
    "  | jq #On passe le résultat à jq pour le formater proprement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd3750-762a-4742-9559-65ed375b1ecb",
   "metadata": {},
   "source": [
    "Reste donc à transformer cela en fonction Python 🙂\n",
    "\n",
    "<span style=\"color: #40d6d1; font-size: 1.2em;\"><strong>💡 Astuce |</strong></span> Dans le résultat de la cellule précédente, on voit que les valeurs des coordonnées sont relativement \"profond\" dans l'objet JSON retourné, appellons le `résultat`. Pour accéder à la latitude, il faut par exemple regarder dans \"results\", puis \"bindings\", puis \"lat\" puis \"value\".  On a donc envie d'écrire `résultat[\"results\"][\"bindings\"][\"lat\"][\"value\"]`. Oui mais voilà : si n'importe laquelle des clés n'existe pas, le code va planter ! On pourrait gérer ça avec des clauses imbriquées `if \"clé\" in résultats[\"...\"]: ...`, mais c'est très lourd.\n",
    "Mais il existe une astuce en utilisant la méthode `résultat.get(\"clé\")` à la place de `résultat[\"clé\"]`. Ces deux formes d'accès au contenu d'un dictionnaires sont presques similaires, sauf que :\n",
    "- `résultat.get(\"clé\")` renvoie `None` si \"clé\" n'est pas une clé du dictionnaire, alors que dans ce cas `résultat[\"clé\"]` lèvera une exception ;\n",
    "- `résultat.get()` accepte un second paramètre qui est la valeur retournée par défaut **si la clé n'existe pas**.\n",
    "\n",
    "L'astuce est alors de retourner un dictionnaire vide dans ce cas, ce qui permet de chainer les appels à `résultat.get` pour parcourir les éléments imbriqués : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d957730-597b-4e7c-85da-8fcd8957c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complétez-moi ! 🏗️\n",
    "\n",
    "\n",
    "@cache  # Mise en cache, les requêtes SPARQL sont coûteuses en temps !\n",
    "def geocode(uri: str) -> tuple[float, float]:\n",
    "\n",
    "    # Le patron de requête SPARQL: l'URI sera substituée à la place de %s par l'argument de la fonction\n",
    "    sparql_template = \"\"\"PREFIX geo: <http://www.w3.org/2003/01/geo/wgs84_pos#> SELECT ?lat ?long WHERE {<%s> (geo:lat) ?lat ; (geo:long) ?long. }\"\"\"\n",
    "\n",
    "    # On substitue l'URI dans le template de requête SPARQL en utilisant le formatage ancien de Python plutôt que les f-strings car la requête SPARQL contient déjà des accolades.\n",
    "    sparql_query = sparql_template % uri\n",
    "\n",
    "    http_headers = {\n",
    "        \"Content-Type\": \"application/sparql-query\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "    response = requests.post(\n",
    "        \"http://fr.dbpedia.org/sparql\", headers=http_headers, data=sparql_query\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    json_response = response.json()\n",
    "\n",
    "    # Récupérer l'élément results -> bindings dans l'objet json_response\n",
    "    # ⚠️ ATTENTION : l'élement \"bindings\" est une liste, donc l'argument par défaut pour get(\"bindings\") doit être une liste vide => get(\"bindings\", [])\n",
    "    bindings = json_response.get(\"results\", {}).get(\"bindings\", [])\n",
    "\n",
    "    # Si la liste \"bindings\" est vide, lat et long seront None\n",
    "    if not bindings:\n",
    "        return None, None\n",
    "\n",
    "    # Sinon, le premier élément de la liste \"bindings\" est un dictionnaire contenant les valeurs de lat et long\n",
    "    bindings = bindings[0]\n",
    "\n",
    "    # Récupérer la valeur de latitude dans : lat -> value\n",
    "    lat = bindings.get(\"lat\", {}).get(\"value\", None)\n",
    "\n",
    "    # Récupérer la valeur de longitude dans : long -> value\n",
    "    long = bindings.get(\"long\", {}).get(\"value\", None)\n",
    "\n",
    "    # lat et long sont récupérés en tant que chaînes de caractères, on les convertit en float\n",
    "    lat = float(lat) or None\n",
    "    long = float(long) or None\n",
    "\n",
    "    return lat, long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25e230-4e25-4af2-bfea-f243bcfccace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi !   🚀\n",
    "\n",
    "uri = \"http://fr.dbpedia.org/resource/Staffordshire\"\n",
    "\n",
    "coordonnees = geocode(uri)\n",
    "print(f\"{uri=} => {coordonnees=}\")\n",
    "\n",
    "assert all(\n",
    "    [\n",
    "        isinstance(coordonnees, tuple),\n",
    "        len(coordonnees) == 2,\n",
    "        all(isinstance(x, float) for x in coordonnees),\n",
    "        coordonnees == (52.8333, -2.0),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6511abe9-ce67-47b5-b884-aa7e6a1dd9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(toponyme: str) -> tuple[float, float]:\n",
    "    uri = dbpedia_top1(toponyme)\n",
    "    if not uri:\n",
    "        lat, long = None, None\n",
    "    else:\n",
    "        lat, long = geocode(uri)\n",
    "    return lat, long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc94e3-133b-4498-8b44-636a59457452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates_verbose(toponyme: str) -> tuple[float, float]:\n",
    "\n",
    "    uri = dbpedia_top1(toponyme)\n",
    "    print(f\"{toponyme=} => {uri=}\", end=\"\")\n",
    "\n",
    "    if not uri:\n",
    "        lat, long = None, None\n",
    "    else:\n",
    "        lat, long = geocode(uri)\n",
    "\n",
    "    print(f\" => {lat=}, {long=}\")\n",
    "    return lat, long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1704b8-e0e4-4dff-9a6b-8f3647b661b0",
   "metadata": {},
   "source": [
    " <div style=\"border-bottom: 1px solid #ff9800; padding: 10px; border-radius: 5px; margin-top: -30px;\"></div>\n",
    "\n",
    "## Reconnaître automatiquement et cartographier les lieux d'un texte\n",
    "\n",
    "<span style=\"color: #85d0ff; font-size: 1.2em;\"><strong>ℹ️ Info |</strong></span> Cette seconde partie ne contient pas de question mais est un tutorial pour appliquer la chaîne de traitement construire à des textes dont les lieux sont reconnus à l'aide du modèle SpaCy entraîné dans la partie 1.\n",
    "\n",
    "\n",
    "### Premier essai\n",
    "\n",
    "\n",
    "L'idée est maintenant de pouvoir appliquer la chaîne de traitement à toutes les entités LOC extraites d'un texte historique par le modèles SpaCy entraîné dans la partie 1 !\n",
    "\n",
    "\n",
    "Commençons par charger le modèle, qui devrait se trouver dans le dossier `../partie_1/ner_presse_ancienne/model-best`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457cc4b-1d05-461e-bec9-47f009e737a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"ner/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70643fd1-df9b-4f0e-87c7-f2dfba8407b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "# Même traitement que précédemment mais avec un meilleur modèle\n",
    "\n",
    "from IPython import display\n",
    "from spacy import displacy\n",
    "\n",
    "with open(\"docs/bpt6k65591428.txt\", \"r\") as file:\n",
    "    texte = file.read()\n",
    "\n",
    "doc = nlp(texte)\n",
    "display.HTML(displacy.render(doc, style=\"ent\", jupyter=False, page=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ed8336-dd55-4b94-a4b7-4673ab752813",
   "metadata": {},
   "source": [
    "Le modèle prédit des entités de différentes classes (ORG, PER, LOC), mais nous ne sommes intéressés que par les lieux (LOC).\n",
    "Filtrons donc les entités nommées reconnues pour ne ressortir que les lieux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fcd1d8-d51b-4920-b469-3a07ac60320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = [ent.text for ent in doc.ents if ent.label_ == \"LOC\"]\n",
    "loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0870b46-264e-4d79-a4aa-ff6d9d20cb44",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant exécuter la chaîne de traitement de résolution de toponymes pour chaque entité nommée LOC !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff1a84-f6d5-4ea0-b9a7-d3cd05e9c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "for toponyme in loc:\n",
    "    get_coordinates_verbose(toponyme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6115bf5e-b210-4af3-9e49-482c292be676",
   "metadata": {},
   "source": [
    "### Géocodage d'un texte\n",
    "\n",
    "Nous voici capables de récupérer les coordonnées des lieux dans un texte grâce à SpaCY et notre chaîne de traitement !\n",
    "\n",
    "Afin de réutiliser le mécanisme complet, créons une fonction `geocode_texte(texte: str, model: spacy.language.Language) -> tuple[list, list]` qui :\n",
    "- prend en argument un texte quelconque et le modèle SpaCy\n",
    "- renvoie deux listes : une liste de toutes les mentions de lieux reconnus, et une liste des paires de coordonnées identifiées pour chacun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8978fd-8887-460d-950a-573b4ebcec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "def geocode_texte(\n",
    "    text: str, nlp: spacy.language.Language\n",
    ") -> tuple[list[str], list[tuple[float, float]]]:\n",
    "    doc = nlp(text)\n",
    "    loc = [ent.text for ent in doc.ents if ent.label_ == \"LOC\"]\n",
    "    coordonnees = [get_coordinates(toponyme) for toponyme in loc]\n",
    "    return loc, coordonnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a86249e-b872-4e86-a088-8bed74b85a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d1e0d1-5e4e-4217-8098-b17cef45257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "loc_dict = dict(Counter(loc)) # dédoublonner la liste des lieux avec un compteur, dans un dict\n",
    "# ajouter les coordonnées de chaque lieu dans le dict\n",
    "for k,v in loc_dict.items():\n",
    "    loc_dict[k]=[loc_dict[k], dbpedia_top1(k), get_coordinates(k)]\n",
    "# ajouter url et coordonnées pour chaque lieu\n",
    "df = pd.DataFrame.from_dict(loc_dict, orient='index',\n",
    "                           columns=['occs', 'db_pedia', 'coordinates'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf4303-b837-4676-90fb-b6581062a4a0",
   "metadata": {},
   "source": [
    "## Cartographie avec Folium\n",
    "\n",
    "\n",
    "Folium est une bibliothèque Python pour créer des cartes interactives extrêmement facilement; nous allons l'utiliser pour afficher la densité des mentions de toponymes localisés sous la forme d'une **carte de chaleur interactive** !\n",
    "\n",
    "Commençons par installer puis importer Folium ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c96f4d-255c-4495-9895-bb5dba216e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "%pip install -q folium\n",
    "\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f2086a-ca52-4534-9101-73260946940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "folium_map = folium.Map(\n",
    "    location=[48.8566, 2.3522],  # On précise les coordonnées du centre de la carte...\n",
    "    zoom_start=3,  # ... et le niveau de zoom initial. 0 = vue du monde, 18 = vue très rapprochée\n",
    ")\n",
    "\n",
    "# On affiche l'objet Map\n",
    "folium_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525efc85-1c7a-4cb8-b17e-e8944e1266a3",
   "metadata": {},
   "source": [
    "Ajouter des couches cartographiques est également très facile.\n",
    "\n",
    "Pour créer une carte de chaleur, il suffit de créer un objet de type `HeatMap`, disponible dans le module `folium.plugins`.\n",
    "\n",
    "L'objectif est donc de créer une carte de chaleur à partir des lieux géocodées dans un texte grâce à  `geocode_texte()`.\n",
    "\n",
    "Le constructeur de `HeatMap` accepte une liste de coordonnées géographiques **valides**. Nous devons donc préalablement retirer les paires de coordnnées `(None, None)` potentiellement produites par la chaîne de traitement lorsque des toponymes ne sont pas résolus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283831e-9bd2-407b-953c-d0ea3ff14173",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coordonnees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc712c-701c-49b6-a2b6-e399e9eb1d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "coordonnees_valides = [(lat, long) for lat, long in coordonnees if lat and long]\n",
    "\n",
    "print(\"Coordonnées valides :\", len(coordonnees_valides), \"/\", len(coordonnees))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa54074a-9b1a-45fc-8515-266c609d2b36",
   "metadata": {},
   "source": [
    "Il ne reste plus qu'à créer un objet `HeatMap` à partir de ces coordonnées valides, puis l'ajouter à la carte !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454b107-1388-4bb0-99cd-1e2f98295d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# On crée une carte de chaleur à partir des coordonnées valides\n",
    "heatmap = HeatMap(coordonnees_valides)\n",
    "\n",
    "# On ajoute la carte de chaleur à la carte folium\n",
    "heatmap.add_to(folium_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7203603-67f6-4684-a34e-1cafe3f870fd",
   "metadata": {},
   "source": [
    "Ce qui permet de construire la projection cartographique finale des mentions de lieux identifiés dans le texte de presse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d159a4fa-1335-4f11-8c5b-416b4d16bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "folium_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e46ea82-7460-4c7a-9b19-fb3521cb898d",
   "metadata": {},
   "source": [
    "## Une App Dash pour tester le code\n",
    "\n",
    "Si vous voulez expérimenter d'avantage, **lancez l'application Dash dashboard.py** qui réutilise le code créé ici et permet de projeter sur une carte un texte récupéré depuis Gallica grâce à son [API Document](https://api.bnf.fr/fr/api-document-de-gallica) ! \n",
    "\n",
    "Dans cette application, on peut rapidement comparer les cartes générées pour 2 publications successives :\n",
    "\n",
    "- https://gallica.bnf.fr/ark:/12148/bpt6k65591428 => ICOM 1964 (première mention du Festival mondial des arts nègres)\n",
    "- https://gallica.bnf.fr/ark:/12148/bpt6k6567411d => ICOM 1968 (nouvelles mention du Festival et pour comparaison des cartes mondiales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75822ab-b4a1-45cf-a46b-96a75c942c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "# ! conda install -c conda-forge dash-bootstrap-components\n",
    "! python3 dashboard.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa91153-0a41-483c-a13c-ee4e442a51d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595f2b16-c253-4e16-a365-5c6db81da61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "url = 'https://gallica.bnf.fr/SRU?version=1.2&operation=searchRetrieve&query=gallica%20all%20%22FESTAC%22%20sortby%20ocr.quality/sort.descending&filter=dc.type%20all%20%22fascicule%22%20and%20dc.language%20all%20%22fre%22%20and%20dc.date%20%3E=%20%221976%22'\n",
    "urllib.parse.unquote(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
